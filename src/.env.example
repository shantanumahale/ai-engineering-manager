# AI Engineering Manager - Environment Configuration
# Copy this file to .env and fill in your values

# ===================
# JIRA Configuration
# ===================
JIRA_BASE_URL=https://your-company.atlassian.net
JIRA_EMAIL=your-email@company.com
JIRA_API_TOKEN=your-jira-api-token
JIRA_PROJECT_KEY=PROJ

# ===================
# Slack Configuration
# ===================
# Bot User OAuth Token (starts with xoxb-)
SLACK_BOT_TOKEN=xoxb-your-bot-token

# App-Level Token for Socket Mode (starts with xapp-)
SLACK_APP_TOKEN=xapp-your-app-token

# Signing Secret from Slack App settings
SLACK_SIGNING_SECRET=your-signing-secret

# Channel for standups (include the #)
SLACK_STANDUP_CHANNEL=#product-x-engineers

# ===================
# LLM Provider Selection
# ===================
# Choose your LLM provider: 'anthropic', 'openai', or 'ollama'
# Anthropic (Claude) is recommended for organization setups
LLM_PROVIDER=anthropic

# ===================
# Anthropic Configuration (Recommended for Org)
# ===================
# Custom base URL (for organization proxies)
ANTHROPIC_BASE_URL=https://api.anthropic.com
# Or use your organization-provided base URL:
# ANTHROPIC_BASE_URL=https://your-org-proxy.example.com

# API key (use ANTHROPIC_AUTH_TOKEN or ANTHROPIC_API_KEY)
ANTHROPIC_AUTH_TOKEN=your-anthropic-api-key

# Model options:
# - claude-sonnet-4-20250514 (recommended: balanced)
# - claude-opus-4-5-20251101 (most capable)
# - Or your org's model identifier
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Request timeout in milliseconds
ANTHROPIC_TIMEOUT=60000

# ===================
# OpenAI Configuration (Alternative)
# ===================
# Custom base URL (for organization proxies or Azure OpenAI)
# Leave empty or comment out to use default: https://api.openai.com/v1
# OPENAI_BASE_URL=https://your-org-proxy.example.com/v1

# Get your API key from: https://platform.openai.com/api-keys
# Or use your organization-provided API key
OPENAI_API_KEY=sk-your-openai-api-key

# Model options:
# - gpt-4o-mini (recommended: fast, cheap, capable)
# - gpt-3.5-turbo (cheaper, slightly less capable)
# - gpt-4o (most capable, more expensive)
OPENAI_MODEL=gpt-4o-mini

# Request timeout in milliseconds
OPENAI_TIMEOUT=60000

# ===================
# Ollama Configuration (Alternative - Local Models)
# ===================
# Use this if you prefer running models locally
# Ollama server URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Model to use (recommended: llama3.3:70b for best reasoning)
# Other options: llama3.1:70b, llama3:70b, mixtral:8x7b
OLLAMA_MODEL=llama3.3:70b

# Request timeout in milliseconds
OLLAMA_TIMEOUT=120000

# ===================
# Standup Schedule (IST)
# ===================
# Hour in 24-hour format (0-23)
STANDUP_HOUR=9

# Minute (0-59)
STANDUP_MINUTE=30

# Maximum back-and-forth conversations per developer before offering 1-1 follow-up
# After this many exchanges, the bot will offer to connect 1-1 separately
STANDUP_MAX_CONVERSATIONS=3

# Team members to exclude from standup (non-developers like EM, PM)
# Comma-separated list of names (case-insensitive, partial match)
# Example: Keshav (EM), Sushma (PM) will be skipped
STANDUP_EXCLUDED_MEMBERS=Keshav,Sushma

# ===================
# App Configuration
# ===================
# Data directory for storing leave records etc.
DATA_DIR=./data

# Debug mode (true/false)
DEBUG=false
